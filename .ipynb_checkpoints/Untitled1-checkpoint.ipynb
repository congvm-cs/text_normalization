{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phonetics\n",
    "import fuzzy\n",
    "import cmudict\n",
    "import eng_to_ipa as ipa\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_dict = dict(cmudict.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = [\"ʌ\",\"ɑ\",\"æ\",\"e\",\"ə\",\"ɜ\",\"ɪ\",\"i\",\"ɒ\",\"ɔ\",\"ʊ\",\"u\",\"aɪ\",\"aʊ\",\"eɪ\",\"oʊ\",\"ɔɪ\",\"eə\",\"ɪə\",\"ʊə\",\"b\",\"d\",\"f\",\"g\",\"h\",\"j\",\"k\",\"l\",\"m\",\"n\",\"ŋ\",\"p\",\"r\",\"ɹ\", \"s\",\"ʃ\",\"t\",\"tʃ\",\"θ\",\"ð\",\"v\",\"w\",\"z\",\"ʒ\",\"dʒ\"]\n",
    "\n",
    "def preprocess(word):\n",
    "    \"\"\"Returns a string of words stripped of punctuation\"\"\"\n",
    "    punct_str = '!\"#$%&\\'()*+,-./:;<=>/?@[\\\\]^_`{|}~«» '\n",
    "    return word.strip(punct_str).lower()\n",
    "\n",
    "def get_ipa(word, core='espeak'):\n",
    "    word = preprocess(word)\n",
    "#     print(word)\n",
    "    \n",
    "    if core == \"espeak\":\n",
    "        cmd = \"espeak {} --ipa=1\".format(word)\n",
    "        result = subprocess.run(cmd.split(), stdout=subprocess.PIPE)\n",
    "        result = result.stdout.split()[0].decode('utf-8')\n",
    "        print(result)\n",
    "    else:\n",
    "        result = ipa.convert(word)\n",
    "    \n",
    "    ret = \"\"\n",
    "    for i in result:\n",
    "        if (i in keep_list) or (i in consonant_list):\n",
    "            ret += i\n",
    "    return ret\n",
    "\n",
    "def ipa_to_viet(ipa_form):\n",
    "    ret_= \"\"\n",
    "    curren_idx = 0\n",
    "    while curren_idx < len(ipa_form):\n",
    "        if ipa_form[curren_idx:curren_idx+2] in map_dict:\n",
    "            ret_ += map_dict[ipa_form[curren_idx:curren_idx+2]]\n",
    "            curren_idx += 2\n",
    "        elif ipa_form[curren_idx] in map_dict:\n",
    "            ret_ += map_dict[ipa_form[curren_idx]]\n",
    "            curren_idx += 1\n",
    "        else:\n",
    "            ret_ += ipa_form[curren_idx]\n",
    "            curren_idx += 1\n",
    "    return ret_\n",
    "\n",
    "\n",
    "def remove_spec_punc(word):\n",
    "    ret_= []\n",
    "    for i in result:\n",
    "        tmp = \"\"\n",
    "        for j in i:\n",
    "            if j != spec_pun:\n",
    "                tmp += j\n",
    "        ret_.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ipa_q(word, core='espeak'):\n",
    "    word = preprocess(word)\n",
    "    if core == \"espeak\":\n",
    "        cmd = \"espeak {} --ipa=1\".format(word)\n",
    "        result = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "        result = result.stdout.split()[0].decode('utf-8')\n",
    "    else:\n",
    "        result = ipa.convert(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_chars = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"English is a West Germanic language that was first spoken in early medieval England and is now the third most widespread native language in the world after Standard Chinese and Spanish as well as the most widely spoken Germanic language Welcome to the WikiWikiWeb, also known as. A lot of people had their first wiki experience here. This community has been around since 1995 and consists of many people. We always accept newcomers with valuable contributions. If you haven't used a wiki before, be prepared for a bit of CultureShock. The usefulness of Wiki is in the freedom, simplicity, and power it offers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"English is a West Germanic language that was first spoken in early medieval England and is now the third most widespread native language in the world after Standard Chinese and Spanish as well as the most widely spoken Germanic language Welcome to the WikiWikiWeb, also known as. A lot of people had their first wiki experience here. This community has been around since 1995 and consists of many people. We always accept newcomers with valuable contributions. If you haven't used a wiki before, be prepared for a bit of CultureShock. The usefulness of Wiki is in the freedom, simplicity, and power it offers.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = preprocess(word=words).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english',\n",
       " 'is',\n",
       " 'a',\n",
       " 'west',\n",
       " 'germanic',\n",
       " 'language',\n",
       " 'that',\n",
       " 'was',\n",
       " 'first',\n",
       " 'spoken',\n",
       " 'in',\n",
       " 'early',\n",
       " 'medieval',\n",
       " 'england',\n",
       " 'and',\n",
       " 'is',\n",
       " 'now',\n",
       " 'the',\n",
       " 'third',\n",
       " 'most',\n",
       " 'widespread',\n",
       " 'native',\n",
       " 'language',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'after',\n",
       " 'standard',\n",
       " 'chinese',\n",
       " 'and',\n",
       " 'spanish',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'most',\n",
       " 'widely',\n",
       " 'spoken',\n",
       " 'germanic',\n",
       " 'language',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'wikiwikiweb,',\n",
       " 'also',\n",
       " 'known',\n",
       " 'as.',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'people',\n",
       " 'had',\n",
       " 'their',\n",
       " 'first',\n",
       " 'wiki',\n",
       " 'experience',\n",
       " 'here.',\n",
       " 'this',\n",
       " 'community',\n",
       " 'has',\n",
       " 'been',\n",
       " 'around',\n",
       " 'since',\n",
       " '1995',\n",
       " 'and',\n",
       " 'consists',\n",
       " 'of',\n",
       " 'many',\n",
       " 'people.',\n",
       " 'we',\n",
       " 'always',\n",
       " 'accept',\n",
       " 'newcomers',\n",
       " 'with',\n",
       " 'valuable',\n",
       " 'contributions.',\n",
       " 'if',\n",
       " 'you',\n",
       " \"haven't\",\n",
       " 'used',\n",
       " 'a',\n",
       " 'wiki',\n",
       " 'before,',\n",
       " 'be',\n",
       " 'prepared',\n",
       " 'for',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'cultureshock.',\n",
       " 'the',\n",
       " 'usefulness',\n",
       " 'of',\n",
       " 'wiki',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'freedom,',\n",
       " 'simplicity,',\n",
       " 'and',\n",
       " 'power',\n",
       " 'it',\n",
       " 'offers']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "from eng_to_ipa import transcribe\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import eng_to_ipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_to_ipa.syllable_count('medieval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['S', 'P', 'OW1', 'K', 'AH0', 'N']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_dict['spoken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spec_pun' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e0c603f74e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_spec_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_spec_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-ed9b3240c828>\u001b[0m in \u001b[0;36mremove_spec_punc\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec_pun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mtmp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mret_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spec_pun' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(words):\n",
    "    cmd = \"espeak {} --ipa=1\".format(word)\n",
    "    result = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "    result = result.stdout.read().decode('utf-8').split(\"\\n\")[0].split(\"_\")\n",
    "    print(idx, word, remove_spec_punc(result), \"\".join([i for i in mapping(remove_spec_punc(result))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_pun_ipa_list = [712, 716]\n",
    "# , 720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spec_punc(word):\n",
    "    ret_= []\n",
    "    for i in result:\n",
    "        tmp = \"\"\n",
    "        for j in i:\n",
    "            if ord(j) not in removed_pun_ipa_list:\n",
    "                tmp += j\n",
    "        ret_.append(tmp)\n",
    "    return ret_\n",
    "\n",
    "def mapping(word):\n",
    "    ret_= []\n",
    "    for w in word:\n",
    "        ret_.append(map_dict[w] if w in map_dict else w)\n",
    "    return ret_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'map_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c3e3ba9c978c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_spec_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_spec_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-b2c72b6501bc>\u001b[0m in \u001b[0;36mmapping\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mret_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mret_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'map_dict' is not defined"
     ]
    }
   ],
   "source": [
    "word = \"metal\"\n",
    "word = \"lunch\"\n",
    "cmd = \"espeak {} --ipa=1\".format(word)\n",
    "result = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "result = result.stdout.read().decode('utf-8').split(\"\\n\")[0].split(\"_\")\n",
    "print(idx, word, result, remove_spec_punc(result), \"\".join([i for i in mapping(remove_spec_punc(result))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('ˌ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipa_to_viet(ipa_form):\n",
    "    ret_= []\n",
    "    curren_idx = 0\n",
    "    while curren_idx < len(ipa_form):\n",
    "        if ipa_form[curren_idx:curren_idx+2] in viet_compound_alpha:\n",
    "            ret_ += ipa_form[curren_idx:curren_idx+2]\n",
    "            curren_idx += 2\n",
    "        elif ipa_form[curren_idx] in viet_compound_alpha:\n",
    "            ret_ += ipa_form[curren_idx]\n",
    "            curren_idx += 1\n",
    "        else:\n",
    "            ret_ += ipa_form[curren_idx]\n",
    "            curren_idx += 1\n",
    "    return ret_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['l', 'â', 'n', 'c', 'h']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa_to_viet('lânch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.antimoon.com/how/pronunc-soundsipa.htm\n",
    "map_dict = {\n",
    "    \"iə\": \"i ơ\",\n",
    "    \"ɐ\": \"a\",\n",
    "    \"əʊ\": \"âu\",\n",
    "    \"ʌ\":    \"â\",\n",
    "    \"ɑː\": \"a\",\n",
    "    \"ɑ\":    \"o\",\n",
    "    \"æ\":    \"a\",\n",
    "    \"e\":    \"e\",\n",
    "    \"ə\":    \"ơ\",\n",
    "    \"ɜ\":    \"ơ\",\n",
    "    \"ɪ\":    \"i\",\n",
    "    \"i\":    \"i\",\n",
    "    \"ɒ\":    \"o\",\n",
    "    \"ɔ\":    \"ô\",\n",
    "    \"ʊ\":    \"u\",\n",
    "    \"u\":    \"u\",\n",
    "    \"aɪ\":   \"ai\",\n",
    "    \"aʊ\":   \"ao\",\n",
    "    \"eɪ\":   \"ây\",\n",
    "    \"oʊ\":   \"âu\", # go >< home\n",
    "    \"ɔɪ\":   \"oi\",\n",
    "    \"eə\":   \"e\",\n",
    "    \"ɪə\":   \"ia\",\n",
    "    \"ʊə\":   \"ua\",\n",
    "    \"b\":    \"b\",\n",
    "    \"d\":    \"đ\",\n",
    "    \"f\":    \"ph\",\n",
    "    \"g\":    \"g\",\n",
    "    \"h\":    \"h\",\n",
    "    \"j\":    \"d\",\n",
    "    \"k\":    \"c\",\n",
    "    \"l\":    \"l\",\n",
    "    \"m\":    \"m\",\n",
    "    \"n\":    \"n\",\n",
    "    \"ŋ\":    \"n\",\n",
    "    \"p\":    \"p\",\n",
    "    \"r\":    \"r\",\n",
    "    \"s\":    \"s\",\n",
    "    \"ʃ\":    \"s\",\n",
    "    \"t\":    \"t\",\n",
    "    \"tʃ\":   \"ch\",\n",
    "    \"θ\":    \"th\",\n",
    "    \"ð\":    \"đ\",\n",
    "    \"v\":    \"v\",\n",
    "    \"w\":    \"qu\",\n",
    "    \"z\":    \"d\",\n",
    "    \"ʒ\":    \"d\",\n",
    "    \"dʒ\":   \"ch\", \n",
    "    \"ju\":   \"iu\", # exception\n",
    "    \"ɔk\":   \"óc\",\n",
    "    \"ɑʊ\": \"ao\",\n",
    "    \"tɹ\": \"tr\",\n",
    "    \"ɒs\" : \"ot\",\n",
    "    \"ɪl\": \"iu\", \n",
    "    \"ɪv\": \"i\",\n",
    "    \"əl\": \"ồ\",\n",
    "    \"ɛ\": \"e\",\n",
    "    \"ɹ\" : \"r\",\n",
    "    \"ɜː\": \"ơ\",\n",
    "    \"iː\": \"i\",\n",
    "    \"uː\": \"u\",\n",
    "    \"ɔː\": \"o\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "viet_consonant_apha = [\n",
    " 'b',\n",
    " 'c',\n",
    " 'd',\n",
    " 'đ',\n",
    " 'g',\n",
    " 'h',\n",
    " 'k',\n",
    " 'l',\n",
    " 'n',\n",
    " 'p',\n",
    " 'q',\n",
    " 'r',\n",
    " 's',\n",
    " 't',\n",
    " 'v',\n",
    " 'x']\n",
    "\n",
    "viet_vowel_alpha = ['a','ă', 'â', 'e', 'ê', 'o', 'ô', 'ơ', 'u', 'ư', 'i', 'y']\n",
    "\n",
    "viet_compound_alpha = ['ch', 'gh', 'ph', 'tr', 'th', 'qu', 'kh', 'gi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 language ['l', 'ˈa', 'ŋ', 'ɡ', 'w', 'ɪ', 'dʒ'] ['l', 'a', 'ŋ', 'ɡ', 'w', 'ɪ', 'dʒ'] lanɡquich\n"
     ]
    }
   ],
   "source": [
    "word = \"metal\"\n",
    "word = \"language\"\n",
    "cmd = \"espeak {} --ipa=1\".format(word)\n",
    "result = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "result = result.stdout.read().decode('utf-8').split(\"\\n\")[0].split(\"_\")\n",
    "print(idx, word, result, remove_spec_punc(result), \"\".join([i for i in mapping(remove_spec_punc(result))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_consonant(char):\n",
    "    if char in viet_consonant_apha:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_vowel(char):\n",
    "    if char in viet_vowel_alpha:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipa_to_viet(ipa_form):\n",
    "    ret_= []\n",
    "    curren_idx = 0\n",
    "    while curren_idx < len(ipa_form):\n",
    "        if ipa_form[curren_idx:curren_idx+2] in viet_compound_alpha:\n",
    "            ret_.append(ipa_form[curren_idx:curren_idx+2])\n",
    "            curren_idx += 2\n",
    "        elif ipa_form[curren_idx] in map_dict:\n",
    "            ret_.append(ipa_form[curren_idx:curren_idx+1])\n",
    "            curren_idx += 1\n",
    "        else:\n",
    "            ret_.append(ipa_form[curren_idx:curren_idx])\n",
    "            curren_idx += 1\n",
    "    return ret_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
